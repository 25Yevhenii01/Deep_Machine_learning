![Image1]("./image/1.png")
Входные данные - x1, x2, x3
Веса - w1, w2, w3
Синапсы - связь между входными данными и результатом (в нашем случае 0 и 1)
Веса играют наибольшую роль в переданному результату нейронам
В нашем примере веса будут инициализироваться генератором случайных чисел
Если бы мы нашли идеальные веса, то дальнейшее обучение нейронной сети и не требовалось бы
Сам процесс обучения - старт с неправильной позиции и в посиках правильной. При этом важен тот факт, что начальные веса не могут быть одинаковыми
Именно благодаря весам нейрон будет определять результат
Нейрон в свою очередь определяет результат при помощи двух действий
1. Умножение входных данных на их веса с дальнейшим сложением чисел - получившийся результат мы передаем в функцию активатор
Функций активаторов довольно много, но в учебных целях используют линейную функцию (единичный скачок, жесткая пороговая функция)
Мы приминяем - сигмоид
![Image2]("./image/2.png")

- Устанавливаем модуль numpy - помогает высокопроизводительно работать с многомерными массивами

Чтобы приблизить веса к более верным значениям нужно прогнать через обучение
1. (Используется)Обратное распространение(самый популярный метод обучения - подразумевает многократное обучение) 2. Упругое распространение 3. Генетический алгоритм
![Image1](image/1.png)
<br>Входные данные - x1, x2, x3<br>
Веса - w1, w2, w3<br>
Синапсы - связь между входными данными и результатом (в нашем случае 0 и 1)<br>
Веса играют наибольшую роль в переданному результату нейронам<br>
В нашем примере веса будут инициализироваться генератором случайных чисел<br>
Если бы мы нашли идеальные веса, то дальнейшее обучение нейронной сети и не требовалось бы<br>
Сам процесс обучения - старт с неправильной позиции и в поисках правильной. При этом важен тот факт, что начальные веса не могут быть одинаковыми<br>
Именно благодаря весам нейрон будет определять результат<br>
Нейрон в свою очередь определяет результат при помощи двух действий<br>
1. Умножение входных данных на их веса с дальнейшим сложением чисел - получившийся результат мы передаем в функцию активатор
Функций активаторов довольно много, но в учебных целях используют линейную функцию (единичный скачок, жесткая пороговая функция)
Мы применяем - сигмоид<br>
![Image2](image/2.png)

- Модуль numpy - помогает высокопроизводительно работать с многомерными массивами

Чтобы приблизить веса к более верным значениям нужно прогнать через обучение<br>
1. (Используется)Обратное распространение(самый популярный метод обучения - подразумевает многократное обучение) 2. Упругое распространение 3. Генетический алгоритм